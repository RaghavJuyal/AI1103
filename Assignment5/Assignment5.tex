\documentclass[journal,12pt,twocolumn]{IEEEtran}

\usepackage{setspace}
\usepackage{gensymb}
\singlespacing
\usepackage[cmex10]{amsmath}

\usepackage{amsthm}

\usepackage{mathrsfs}
\usepackage{txfonts}
\usepackage{stfloats}
\usepackage{bm}
\usepackage{cite}
\usepackage{cases}
\usepackage{subfig}

\usepackage{longtable}
\usepackage{multirow}

\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{steinmetz}
\usepackage{tikz}
\usepackage{circuitikz}
\usepackage{verbatim}
\usepackage{tfrupee}
\usepackage[breaklinks=true]{hyperref}
\usepackage{graphicx}
\usepackage{tkz-euclide}


\usetikzlibrary{calc,math}
\usepackage{listings}
    \usepackage{color}                                            %%
    \usepackage{array}                                            %%
    \usepackage{longtable}                                        %%
    \usepackage{calc}                                             %%
    \usepackage{multirow}                                         %%
    \usepackage{hhline}                                           %%
    \usepackage{ifthen}                                           %%
    \usepackage{lscape}     
\usepackage{multicol}
\usepackage{chngcntr}

\DeclareMathOperator*{\Res}{Res}

\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\thesection.\arabic{subsection}}
\renewcommand\thesubsubsection{\thesubsection.\arabic{subsubsection}}

\renewcommand\thesectiondis{\arabic{section}}
\renewcommand\thesubsectiondis{\thesectiondis.\arabic{subsection}}
\renewcommand\thesubsubsectiondis{\thesubsectiondis.\arabic{subsubsection}}



\hyphenation{op-tical net-works semi-conduc-tor}
\def\inputGnumericTable{}                                 %%

\lstset{
%language=C,
frame=single, 
breaklines=true,
columns=fullflexible
}
\begin{document}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}{Example}[section]
\newtheorem{definition}[problem]{Definition}

\newcommand{\BEQA}{\begin{eqnarray}}
\newcommand{\EEQA}{\end{eqnarray}}
\newcommand{\define}{\stackrel{\triangle}{=}}
\bibliographystyle{IEEEtran}
\raggedbottom
\setlength{\parindent}{0pt}
\providecommand{\mbf}{\mathbf}
\providecommand{\pr}[1]{\ensuremath{\Pr\left(#1\right)}}
\providecommand{\qfunc}[1]{\ensuremath{Q\left(#1\right)}}
\providecommand{\sbrak}[1]{\ensuremath{{}\left[#1\right]}}
\providecommand{\lsbrak}[1]{\ensuremath{{}\left[#1\right.}}
\providecommand{\rsbrak}[1]{\ensuremath{{}\left.#1\right]}}
\providecommand{\brak}[1]{\ensuremath{\left(#1\right)}}
\providecommand{\lbrak}[1]{\ensuremath{\left(#1\right.}}
\providecommand{\rbrak}[1]{\ensuremath{\left.#1\right)}}
\providecommand{\cbrak}[1]{\ensuremath{\left\{#1\right\}}}
\providecommand{\lcbrak}[1]{\ensuremath{\left\{#1\right.}}
\providecommand{\rcbrak}[1]{\ensuremath{\left.#1\right\}}}
\theoremstyle{remark}
\newtheorem{rem}{Remark}
\newcommand{\sgn}{\mathop{\mathrm{sgn}}}
\providecommand{\abs}[1]{\vert#1\vert}
\providecommand{\res}[1]{\Res\displaylimits_{#1}} 
\providecommand{\norm}[1]{\lVert#1\rVert}
%\providecommand{\norm}[1]{\lVert#1\rVert}
\providecommand{\mtx}[1]{\mathbf{#1}}
\providecommand{\mean}[1]{E[ #1 ]}
\providecommand{\fourier}{\overset{\mathcal{F}}{ \rightleftharpoons}}
%\providecommand{\hilbert}{\overset{\mathcal{H}}{ \rightleftharpoons}}
\providecommand{\system}{\overset{\mathcal{H}}{ \longleftrightarrow}}
	%\newcommand{\solution}[2]{\textbf{Solution:}{#1}}
\newcommand{\solution}{\noindent \textbf{Solution: }}
\newcommand{\cosec}{\,\text{cosec}\,}
\providecommand{\dec}[2]{\ensuremath{\overset{#1}{\underset{#2}{\gtrless}}}}
\newcommand*{\permcomb}[4][0mu]{{{}^{#3}\mkern#1#2_{#4}}}
\newcommand*{\perm}[1][-3mu]{\permcomb[#1]{P}}
\newcommand*{\comb}[1][-1mu]{\permcomb[#1]{C}}
\newcommand{\myvec}[1]{\ensuremath{\begin{pmatrix}#1\end{pmatrix}}}
\newcommand{\mydet}[1]{\ensuremath{\begin{vmatrix}#1\end{vmatrix}}}
\numberwithin{equation}{subsection}
\makeatletter
\@addtoreset{figure}{problem}
\makeatother
\let\StandardTheFigure\thefigure
\let\vec\mathbf
\renewcommand{\thefigure}{\theproblem}
\def\putbox#1#2#3{\makebox[0in][l]{\makebox[#1][l]{}\raisebox{\baselineskip}[0in][0in]{\raisebox{#2}[0in][0in]{#3}}}}
     \def\rightbox#1{\makebox[0in][r]{#1}}
     \def\centbox#1{\makebox[0in]{#1}}
     \def\topbox#1{\raisebox{-\baselineskip}[0in][0in]{#1}}
     \def\midbox#1{\raisebox{-0.5\baselineskip}[0in][0in]{#1}}
\vspace{3cm}
\title{Assignment 5}
\author{Raghav Juyal - EP20BTECH11018}
\maketitle
\newpage
\bigskip
\renewcommand{\thefigure}{\theenumi}
\renewcommand{\thetable}{\theenumi}
Download latex-tikz codes from 
%
\begin{lstlisting}
https://github.com/RaghavJuyal/AI1103/tree/main/Assignment5/Assignment5.tex
\end{lstlisting}

\section*{Question 113, CSIR UGC NET EXAM (Dec 2014)}
Let $X_1,X_2,...,X_n$ be independent and identically distributed Bernoulli($\theta$), where $0<\theta<1$ and $n>1$. Let the prior density of $\theta$ be proportional to $\frac{1}{\sqrt{\theta\,(1-\theta)}}$, $0<\theta<1$. Define $S=\sum_{i=1}^nX_i$.\\[1pt] Then valid statements among the following are:
\begin{enumerate}[label = \arabic*.]
    \item The posterior mean of $\theta$ does not exist;
    \item The posterior mean of $\theta$ exists;
    \item The posterior mean of $\theta$ exists and it is larger than the maximum likelihood estimator for all values of S.
    \item The posterior mean of $\theta$ exists and it is larger than the maximum likelihood estimator for some values of S.
\end{enumerate}
\section*{Solution}

\begin{definition}
Posterior mean is the mean of the posterior distribution of $\theta$, i.e., 
\begin{align}
    E\brak{\theta|X} = \int{\theta\;f\brak{\theta|X}\,d\theta}\label{eq5}
\end{align}
\end{definition}

\begin{definition}
The beta function, $B\brak{x,y}$, is defined by the integral
\begin{align}
    B\brak{x,y} &= \int_0^1 t^{x-1}\,\brak{1-t}^{y-1}\,dt\nonumber\\
    &= \frac{x+y}{xy}\times \frac{1}{\comb{x+y}{x}}\label{eq1}
\end{align}
where $Re\brak{x}>0$ and $Re\brak{y}>0$.
\end{definition}

Let $f\brak{\theta}$ be the prior density of $\theta$.
\begin{lemma}
\begin{align}
    f\brak{\theta} = \frac{\theta^{-\frac{1}{2}}\,\brak{1-\theta}^{-\frac{1}{2}}}{B\brak{\frac{1}{2},\frac{1}{2}}}\label{eq6}
\end{align}
\end{lemma}

\begin{proof}
\begin{align}
    &f\brak{\theta} \propto \frac{1}{\sqrt{\theta\,\brak{1-\theta}}}\nonumber\\
    \implies &f\brak{\theta} = \frac{K}{\sqrt{\theta\,\brak{1-\theta}}}
\end{align}
where $K$ is the proportionality constant.
\begin{align}
    &\int_0^1 f\brak{\theta}\,d\theta = 1\nonumber\\
    \implies &K\;\int_0^1 \frac{1}{\sqrt{\theta\,\brak{1-\theta}}}\,d\theta =1
\end{align}
From \eqref{eq1} we get,
\begin{align}
    &K\times B\brak{\frac{1}{2},\frac{1}{2}} = 1\nonumber\\
    \implies &K = \frac{1}{B\brak{\frac{1}{2},\frac{1}{2}}}\\
    \therefore\, &f\brak{\theta} = \frac{\theta^{-\frac{1}{2}}\,\brak{1-\theta}^{-\frac{1}{2}}}{B\brak{\frac{1}{2},\frac{1}{2}}}
\end{align}
\end{proof}

\begin{definition}
The likelihood function refers to the joint probability of the data in the case of discrete distributions and joint probability density of the data in the case of continuous distributions, i.e., 
\begin{align}
    f\brak{X|\theta} = \prod_{i=1}^n f\brak{X_i|\theta}\label{eq8}
\end{align}
\end{definition}

\begin{lemma}
\begin{align}
    f\brak{X|\theta}=\theta^S\,\brak{1-\theta}^{n-S}\label{eq7}
\end{align}
\end{lemma}

\begin{proof}
From \eqref{eq8} we get,
\begin{align}
    f\brak{X|\theta} &= \prod_{i=1}^n\theta^{X_i}\,\brak{1-\theta}^{1-X_i}\nonumber\\
    &=\theta^S\,\brak{1-\theta}^{n-S}
\end{align}
\end{proof}

\begin{definition}
The maximum likelihood estimator is the value which maximizes the likelihood function, i.e.,
\begin{align}
    \text{MLE} = \text{arg$_{\theta \in (0,1)}$ max}\brak{f\brak{X|\theta}}
\end{align}
\end{definition}

\begin{lemma}
\begin{align}
    \text{MLE} = \frac{S}{n}
\end{align}
\end{lemma}

\begin{proof}
Using log of likelihood function and differentiating we get,
\begin{align}
    &\ln\brak{{f\brak{X|\theta}}} = S\ln\brak{{\theta}} + \brak{n-S}\ln\brak{{1-\theta}}\\
    &\frac{\partial \ln\brak{{f\brak{X|\theta}}}}{\partial \theta} = \frac{S}{\theta} + \frac{S-n}{1-\theta} = 0 \nonumber\\
     \therefore\, &\text{MLE} = \frac{S}{n}
\end{align}
\end{proof}

\begin{definition}
The marginal distribution of $x$ is given by
\begin{align}
    f\brak{x} = \int f\brak{x,y}\,dy\label{eq9}
\end{align}
\end{definition}

\begin{definition}
Let $f\brak{\theta|X}$ be the posterior density of $\theta$.
\begin{align}
    f\brak{\theta|X} = \frac{f\brak{X,\theta}}{f\brak{X}}
\end{align}
\end{definition}

\begin{lemma}
\begin{align}
    f\brak{\theta|X} = \frac{\theta^{S-\frac{1}{2}}\,\brak{1-\theta}^{n-S-\frac{1}{2}}}{B\brak{S+\frac{1}{2},n-S+\frac{1}{2}}}
\end{align}
\end{lemma}

\begin{proof}
Using \eqref{eq9} we get,
\begin{align}
    f\brak{\theta|X} &= \frac{f\brak{X,\theta}}{\int_0^1 f\brak{X,\theta}\,d\theta} \nonumber\\
    &= \frac{f\brak{X|\theta}\, f\brak{\theta}}{\int_0^1 f\brak{X|\theta}\, f\brak{\theta}\,d\theta}\label{eq10}
\end{align}
Using \eqref{eq6} and \eqref{eq7} in \eqref{eq10} we get,
\begin{align}
    f\brak{\theta|X} &= \frac{\theta^{S-\frac{1}{2}}\,\brak{1-\theta}^{n-S-\frac{1}{2}}}{\int_0^1 \theta^{S-\frac{1}{2}}\,\brak{1-\theta}^{n-S-\frac{1}{2}}\,d\theta}
\end{align}
Using \eqref{eq1} we get,
\begin{align}
    f\brak{\theta|X} = \frac{\theta^{S-\frac{1}{2}}\,\brak{1-\theta}^{n-S-\frac{1}{2}}}{B\brak{S+\frac{1}{2},n-S+\frac{1}{2}}}
\end{align}
\end{proof}

\begin{corollary}
\begin{align}
    E\brak{\theta|X} = \frac{S+\frac{1}{2}}{n+1}\label{eq3}
\end{align}
\end{corollary}

\begin{proof}
From \eqref{eq5} we get,
\begin{align}
    E\brak{\theta|X} &= \int_0^1 \theta\;f\brak{\theta|X}\,d\theta\nonumber\\
    &=\int_0^1 \frac{\theta^{S+\frac{1}{2}}\,\brak{1-\theta}^{n-S-\frac{1}{2}}}{B\brak{S+\frac{1}{2},n-S+\frac{1}{2}}}\,d\theta\nonumber\\
    &=\frac{B\brak{S+\frac{3}{2},n-S+\frac{1}{2}}}{B\brak{S+\frac{1}{2},n-S+\frac{1}{2}}}\label{eq2}
\end{align}
Using \eqref{eq1} in \eqref{eq2} we get
\begin{align}
    E\brak{\theta|X} = \frac{S+\frac{1}{2}}{n+1}
\end{align}
\end{proof}

\begin{corollary}
For $E\brak{\theta|X}$ to be greater than MLE,
\begin{align}
    n>2\,S\label{eq4}
\end{align}
\end{corollary}

\begin{proof}
\begin{align}
    &\frac{S+\frac{1}{2}}{n+1} > \frac{S}{n}\nonumber\\
     \therefore\;&n>2\,S
\end{align}
\end{proof}

\begin{enumerate}
    \item This option is incorrect since 
    \begin{align*}
        E\brak{\theta|X} = \frac{S+\frac{1}{2}}{n+1} 
    \end{align*}
       from \eqref{eq3} and
    \begin{align*}
        n>1 
    \end{align*}
    given in the question $\implies E\brak{\theta|X}$ exists.
    \item This option is correct since 
    \begin{align*}
        E\brak{\theta|X} = \frac{S+\frac{1}{2}}{n+1} 
    \end{align*}
       from \eqref{eq3} and
    \begin{align*}
        n>1 
    \end{align*}
    given in the question $\implies E\brak{\theta|X}$ exists.
    \item This option is incorrect as from \eqref{eq4} we see that $E\brak{\theta|X}\ngtr\, $MLE$\;\forall$ S.
    \item This option is correct as from \eqref{eq4} we see that $E\brak{\theta|X}>\, $MLE for some values of S.
\end{enumerate}
$\therefore$ Option 2 and 4 are correct.
\end{document}